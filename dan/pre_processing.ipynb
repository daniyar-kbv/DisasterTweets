{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/daniyarkurmanbayev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/daniyarkurmanbayev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import TextVectorization\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(7613, 5)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "              id\ntarget          \n0       22910330\n1       18519120",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n    <tr>\n      <th>target</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22910330</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18519120</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('target').sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3271\n",
      "4342\n"
     ]
    }
   ],
   "source": [
    "print(train[train.target == 1].shape[0])\n",
    "print(train[train.target == 0].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n 'Forest fire near La Ronge Sask. Canada',\n \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\",\n '13,000 people receive #wildfires evacuation orders in California ',\n 'Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ']"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = [train.at[i, 'text'] for i in range(train.shape[0])]\n",
    "train_texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "['Just happened a terrible car crash',\n 'Heard about #earthquake is different cities, stay safe everyone.',\n 'there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all',\n 'Apocalypse lighting. #Spokane #wildfires',\n 'Typhoon Soudelor kills 28 in China and Taiwan']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts = [test.at[i, 'text'] for i in range(test.shape[0])]\n",
    "test_texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "texts = train_texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    return re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "texts = [remove_url(text) for text in texts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "[['Our',\n  'Deeds',\n  'are',\n  'the',\n  'Reason',\n  'of',\n  'this',\n  '#',\n  'earthquake',\n  'May',\n  'ALLAH',\n  'Forgive',\n  'us',\n  'all'],\n ['Forest', 'fire', 'near', 'La', 'Ronge', 'Sask', '.', 'Canada'],\n ['All',\n  'residents',\n  'asked',\n  'to',\n  \"'shelter\",\n  'in',\n  'place',\n  \"'\",\n  'are',\n  'being',\n  'notified',\n  'by',\n  'officers',\n  '.',\n  'No',\n  'other',\n  'evacuation',\n  'or',\n  'shelter',\n  'in',\n  'place',\n  'orders',\n  'are',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'in',\n  'California'],\n ['Just',\n  'got',\n  'sent',\n  'this',\n  'photo',\n  'from',\n  'Ruby',\n  '#',\n  'Alaska',\n  'as',\n  'smoke',\n  'from',\n  '#',\n  'wildfires',\n  'pours',\n  'into',\n  'a',\n  'school']]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [word_tokenize(text) for text in texts]\n",
    "texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "[['Our',\n  'Deeds',\n  'Reason',\n  '#',\n  'earthquake',\n  'May',\n  'ALLAH',\n  'Forgive',\n  'us'],\n ['Forest', 'fire', 'near', 'La', 'Ronge', 'Sask', '.', 'Canada'],\n ['All',\n  'residents',\n  'asked',\n  \"'shelter\",\n  'place',\n  \"'\",\n  'notified',\n  'officers',\n  '.',\n  'No',\n  'evacuation',\n  'shelter',\n  'place',\n  'orders',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'California'],\n ['Just',\n  'got',\n  'sent',\n  'photo',\n  'Ruby',\n  '#',\n  'Alaska',\n  'smoke',\n  '#',\n  'wildfires',\n  'pours',\n  'school']]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [[word for word in text if word not in stopwords.words('english')] for text in texts]\n",
    "texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "[['our',\n  'deeds',\n  'reason',\n  '#',\n  'earthquake',\n  'may',\n  'allah',\n  'forgive',\n  'us'],\n ['forest', 'fire', 'near', 'la', 'ronge', 'sask', '.', 'canada'],\n ['all',\n  'residents',\n  'asked',\n  \"'shelter\",\n  'place',\n  \"'\",\n  'notified',\n  'officers',\n  '.',\n  'no',\n  'evacuation',\n  'shelter',\n  'place',\n  'orders',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'california'],\n ['just',\n  'got',\n  'sent',\n  'photo',\n  'ruby',\n  '#',\n  'alaska',\n  'smoke',\n  '#',\n  'wildfires',\n  'pours',\n  'school']]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [[word.lower() for word in text] for text in texts]\n",
    "texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# spell = SpellChecker()\n",
    "#\n",
    "# texts = [[spell.correction(word) for word in text] for text in texts]\n",
    "# texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "[['our',\n  'deeds',\n  'reason',\n  '#',\n  'earthquake',\n  'may',\n  'allah',\n  'forgive',\n  'us'],\n ['forest', 'fire', 'near', 'la', 'ronge', 'sask', '.', 'canada'],\n ['all',\n  'residents',\n  'asked',\n  \"'shelter\",\n  'place',\n  \"'\",\n  'notified',\n  'officers',\n  '.',\n  'no',\n  'evacuation',\n  'shelter',\n  'place',\n  'orders',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'california'],\n ['just',\n  'got',\n  'sent',\n  'photo',\n  'ruby',\n  '#',\n  'alaska',\n  'smoke',\n  '#',\n  'wildfires',\n  'pours',\n  'school']]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [[contractions.fix(word) for word in text] for text in texts]\n",
    "texts = [' '.join(text).split(' ') for text in texts]\n",
    "texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "'\"$%&\\'()*+,-./:;<=>@[\\\\]^_`{|}~'"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation_cleaned = [symbol for symbol in punctuation if symbol not in '!#?']\n",
    "punctuation_cleaned = ''.join(punctuation_cleaned)\n",
    "punctuation_cleaned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "[['our',\n  'deeds',\n  'reason',\n  '#',\n  'earthquake',\n  'may',\n  'allah',\n  'forgive',\n  'us'],\n ['forest', 'fire', 'near', 'la', 'ronge', 'sask', 'canada'],\n ['all',\n  'residents',\n  'asked',\n  \"'shelter\",\n  'place',\n  'notified',\n  'officers',\n  'no',\n  'evacuation',\n  'shelter',\n  'place',\n  'orders',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'california'],\n ['just',\n  'got',\n  'sent',\n  'photo',\n  'ruby',\n  '#',\n  'alaska',\n  'smoke',\n  '#',\n  'wildfires',\n  'pours',\n  'school']]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [[word for word in text if word not in punctuation_cleaned] for text in texts]\n",
    "texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "['our deeds reason # earthquake may allah forgive us',\n 'forest fire near la ronge sask canada',\n \"all residents asked 'shelter place notified officers no evacuation shelter place orders expected\",\n '13,000 people receive # wildfires evacuation orders california',\n 'just got sent photo ruby # alaska smoke # wildfires pours school']"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [' '.join(text) for text in texts]\n",
    "texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "# X = vectorizer.fit_transform(texts).toarray()\n",
    "# n_words = len(vectorizer.vocabulary_.keys())\n",
    "# print(n_words)\n",
    "# X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 22:13:05.209086: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "vectorizer.adapt(texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "with open('glove/glove.6B.50d.txt') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 12321 words (5443 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "X = np.array(texts)\n",
    "y = train.target.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "np.save('data/X.npy', X)\n",
    "np.save('data/y.npy', y)\n",
    "np.save('data/embedding_matrix.npy', embedding_matrix)\n",
    "np.save('data/num_tokens.npy', num_tokens)\n",
    "np.save('data/embedding_dim.npy', embedding_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
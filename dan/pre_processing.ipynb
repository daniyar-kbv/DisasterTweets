{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/daniyarkurmanbayev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/daniyarkurmanbayev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(7613, 5)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n 'Forest fire near La Ronge Sask. Canada',\n \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\",\n '13,000 people receive #wildfires evacuation orders in California ',\n 'Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = [train.at[i, 'text'] for i in range(train.shape[0])]\n",
    "train_texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['Just happened a terrible car crash',\n 'Heard about #earthquake is different cities, stay safe everyone.',\n 'there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all',\n 'Apocalypse lighting. #Spokane #wildfires',\n 'Typhoon Soudelor kills 28 in China and Taiwan']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts = [test.at[i, 'text'] for i in range(test.shape[0])]\n",
    "test_texts[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "texts = train_texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    return re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "texts = [remove_url(text) for text in texts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[['Our',\n  'Deeds',\n  'are',\n  'the',\n  'Reason',\n  'of',\n  'this',\n  '#',\n  'earthquake',\n  'May',\n  'ALLAH',\n  'Forgive',\n  'us',\n  'all'],\n ['Forest', 'fire', 'near', 'La', 'Ronge', 'Sask', '.', 'Canada'],\n ['All',\n  'residents',\n  'asked',\n  'to',\n  \"'shelter\",\n  'in',\n  'place',\n  \"'\",\n  'are',\n  'being',\n  'notified',\n  'by',\n  'officers',\n  '.',\n  'No',\n  'other',\n  'evacuation',\n  'or',\n  'shelter',\n  'in',\n  'place',\n  'orders',\n  'are',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'in',\n  'California'],\n ['Just',\n  'got',\n  'sent',\n  'this',\n  'photo',\n  'from',\n  'Ruby',\n  '#',\n  'Alaska',\n  'as',\n  'smoke',\n  'from',\n  '#',\n  'wildfires',\n  'pours',\n  'into',\n  'a',\n  'school']]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokenized = [word_tokenize(text) for text in texts]\n",
    "texts_tokenized[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[['Our',\n  'Deeds',\n  'Reason',\n  '#',\n  'earthquake',\n  'May',\n  'ALLAH',\n  'Forgive',\n  'us'],\n ['Forest', 'fire', 'near', 'La', 'Ronge', 'Sask', '.', 'Canada'],\n ['All',\n  'residents',\n  'asked',\n  \"'shelter\",\n  'place',\n  \"'\",\n  'notified',\n  'officers',\n  '.',\n  'No',\n  'evacuation',\n  'shelter',\n  'place',\n  'orders',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'California'],\n ['Just',\n  'got',\n  'sent',\n  'photo',\n  'Ruby',\n  '#',\n  'Alaska',\n  'smoke',\n  '#',\n  'wildfires',\n  'pours',\n  'school']]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_without_stopwords = [[word for word in text if word not in stopwords.words('english')] for text in texts_tokenized]\n",
    "texts_without_stopwords[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[['our',\n  'deeds',\n  'reason',\n  '#',\n  'earthquake',\n  'may',\n  'allah',\n  'forgive',\n  'us'],\n ['forest', 'fire', 'near', 'la', 'ronge', 'sask', '.', 'canada'],\n ['all',\n  'residents',\n  'asked',\n  \"'shelter\",\n  'place',\n  \"'\",\n  'notified',\n  'officers',\n  '.',\n  'no',\n  'evacuation',\n  'shelter',\n  'place',\n  'orders',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'california'],\n ['just',\n  'got',\n  'sent',\n  'photo',\n  'ruby',\n  '#',\n  'alaska',\n  'smoke',\n  '#',\n  'wildfires',\n  'pours',\n  'school']]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_lowercased = [[word.lower() for word in text] for text in texts_without_stopwords]\n",
    "texts_lowercased[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[['our',\n  'deeds',\n  'reason',\n  '#',\n  'earthquake',\n  'may',\n  'allah',\n  'forgive',\n  'us'],\n ['forest', 'fire', 'near', 'la', 'range', 'ask', '.', 'canada'],\n ['all',\n  'residents',\n  'asked',\n  'shelter',\n  'place',\n  \"'\",\n  'notified',\n  'officers',\n  '.',\n  'no',\n  'evacuation',\n  'shelter',\n  'place',\n  'orders',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'california'],\n ['just',\n  'got',\n  'sent',\n  'photo',\n  'ruby',\n  '#',\n  'alaska',\n  'smoke',\n  '#',\n  'wildfires',\n  'pours',\n  'school']]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "texts_corrected = [[spell.correction(word) for word in text] for text in texts_lowercased]\n",
    "texts_corrected[:5]\n",
    "# texts_corrected = texts_lowercased"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[['our',\n  'deeds',\n  'reason',\n  '#',\n  'earthquake',\n  'may',\n  'allah',\n  'forgive',\n  'us'],\n ['forest', 'fire', 'near', 'la', 'range', 'ask', '.', 'canada'],\n ['all',\n  'residents',\n  'asked',\n  'shelter',\n  'place',\n  \"'\",\n  'notified',\n  'officers',\n  '.',\n  'no',\n  'evacuation',\n  'shelter',\n  'place',\n  'orders',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'california'],\n ['just',\n  'got',\n  'sent',\n  'photo',\n  'ruby',\n  '#',\n  'alaska',\n  'smoke',\n  '#',\n  'wildfires',\n  'pours',\n  'school']]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_expanded = [[contractions.fix(word) for word in text] for text in texts_corrected]\n",
    "texts_expanded = [' '.join(text).split(' ') for text in texts_corrected]\n",
    "texts_expanded[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'\"$%&\\'()*+,-./:;<=>@[\\\\]^_`{|}~'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation_cleaned = [symbol for symbol in punctuation if symbol not in '!#?']\n",
    "punctuation_cleaned = ''.join(punctuation_cleaned)\n",
    "punctuation_cleaned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[['our',\n  'deeds',\n  'reason',\n  '#',\n  'earthquake',\n  'may',\n  'allah',\n  'forgive',\n  'us'],\n ['forest', 'fire', 'near', 'la', 'range', 'ask', 'canada'],\n ['all',\n  'residents',\n  'asked',\n  'shelter',\n  'place',\n  'notified',\n  'officers',\n  'no',\n  'evacuation',\n  'shelter',\n  'place',\n  'orders',\n  'expected'],\n ['13,000',\n  'people',\n  'receive',\n  '#',\n  'wildfires',\n  'evacuation',\n  'orders',\n  'california'],\n ['just',\n  'got',\n  'sent',\n  'photo',\n  'ruby',\n  '#',\n  'alaska',\n  'smoke',\n  '#',\n  'wildfires',\n  'pours',\n  'school']]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_without_punctuation = [[word for word in text if word not in punctuation_cleaned] for text in texts_expanded]\n",
    "texts_without_punctuation[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['our deeds reason # earthquake may allah forgive us',\n 'forest fire near la range ask canada',\n 'all residents asked shelter place notified officers no evacuation shelter place orders expected',\n '13,000 people receive # wildfires evacuation orders california',\n 'just got sent photo ruby # alaska smoke # wildfires pours school']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_final = [' '.join(text) for text in texts_without_punctuation]\n",
    "texts_final[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "with open('data/cleaned.pkl', 'wb') as f:\n",
    "    pickle.dump(texts_final, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 1, 1, 1, 1]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [train.at[i, 'target'] for i in range(train.shape[0])]\n",
    "target[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "with open('data/target.pkl', 'wb') as f:\n",
    "    pickle.dump(target, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}